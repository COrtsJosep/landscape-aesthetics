{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807f29bb-b6c5-4e08-8480-abe7cfbab60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   9%|█▎             | 18604/211856 [09:48<1:41:57, 31.59it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m I1, I2, I3 \u001b[38;5;241m=\u001b[39m convert_to_ohta(image_rgb)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Convert to LST color space\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m L, S_lst, T \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_lst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Append the average values of each color space to the results list\u001b[39;00m\n\u001b[1;32m     59\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(image_path),\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(H), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(S), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(V),\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI1_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(I1), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI2_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(I2), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI3_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(I3),\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(L), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS_lst_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(S_lst), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(T)\n\u001b[1;32m     64\u001b[0m })\n",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mconvert_to_lst\u001b[0;34m(image_rgb)\u001b[0m\n\u001b[1;32m     17\u001b[0m R, G, B \u001b[38;5;241m=\u001b[39m image_rgb[:,:,\u001b[38;5;241m0\u001b[39m], image_rgb[:,:,\u001b[38;5;241m1\u001b[39m], image_rgb[:,:,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     18\u001b[0m L \u001b[38;5;241m=\u001b[39m (R \u001b[38;5;241m+\u001b[39m G \u001b[38;5;241m+\u001b[39m B) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3.0\u001b[39m  \u001b[38;5;66;03m# Brightness\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Saturation\u001b[39;00m\n\u001b[1;32m     20\u001b[0m T \u001b[38;5;241m=\u001b[39m (R \u001b[38;5;241m-\u001b[39m B)  \u001b[38;5;66;03m# Hue\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m L, S, T\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "# from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# # Define function: Convert to Ohta color space\n",
    "# def convert_to_ohta(image_rgb):\n",
    "#     R, G, B = image_rgb[:,:,0], image_rgb[:,:,1], image_rgb[:,:,2]\n",
    "#     I1 = (R + G + B) / 3.0  # Brightness component\n",
    "#     I2 = (R - B) / 2.0      # Red-blue difference\n",
    "#     I3 = (2 * G - R - B) / 4.0  # Green-purple difference\n",
    "#     return I1, I2, I3\n",
    "\n",
    "# # Define function: Convert to LST color space\n",
    "# def convert_to_lst(image_rgb):\n",
    "#     R, G, B = image_rgb[:,:,0], image_rgb[:,:,1], image_rgb[:,:,2]\n",
    "#     L = (R + G + B) / 3.0  # Brightness\n",
    "#     S = np.sqrt(((R - G)**2 + (R - B)**2 + (G - B)**2) / 3.0)  # Saturation\n",
    "#     T = (R - B)  # Hue\n",
    "#     return L, S, T\n",
    "\n",
    "# # Read the CSV file\n",
    "# data_path = '/home/ubuntu/landscape-aesthetics/data/external/scenicornot/scenicornot.metadata.csv'\n",
    "# image_folder = Path('/home/ubuntu/landscape-aesthetics/data/external/scenicornot')\n",
    "\n",
    "# data = pd.read_csv(data_path)\n",
    "\n",
    "# # List to store the final results\n",
    "# results = []\n",
    "\n",
    "# # Iterate over each row in the CSV file with tqdm progress bar\n",
    "# for index, row in tqdm(data.iterrows(), total=data.shape[0], desc=\"Processing images\"):\n",
    "#     # Read image path\n",
    "#     image_path = image_folder / row['filename']  # Assuming 'filename' is the column name containing image file names\n",
    "    \n",
    "#     try:\n",
    "#         # Read the image\n",
    "#         image = cv2.imread(str(image_path))\n",
    "        \n",
    "#         if image is None:\n",
    "#             print(f\"Image not found: {image_path}, skipping...\")\n",
    "#             continue\n",
    "        \n",
    "#         # Convert BGR to RGB (OpenCV reads in BGR format by default)\n",
    "#         image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "#         # Convert to HSV color space\n",
    "#         image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#         H, S, V = image_hsv[:,:,0], image_hsv[:,:,1], image_hsv[:,:,2]\n",
    "        \n",
    "#         # Convert to Ohta color space\n",
    "#         I1, I2, I3 = convert_to_ohta(image_rgb)\n",
    "        \n",
    "#         # Convert to LST color space\n",
    "#         L, S_lst, T = convert_to_lst(image_rgb)\n",
    "        \n",
    "#         # Append the average values of each color space to the results list\n",
    "#         results.append({\n",
    "#             'image_path': str(image_path),\n",
    "#             'H_mean': np.mean(H), 'S_mean': np.mean(S), 'V_mean': np.mean(V),\n",
    "#             'I1_mean': np.mean(I1), 'I2_mean': np.mean(I2), 'I3_mean': np.mean(I3),\n",
    "#             'L_mean': np.mean(L), 'S_lst_mean': np.mean(S_lst), 'T_mean': np.mean(T)\n",
    "#         })\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing image {image_path}: {e}\")\n",
    "#         continue  # Skip this image and move to the next one\n",
    "\n",
    "# # Convert results to a DataFrame\n",
    "# output_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save results to a new CSV file\n",
    "# output_df.to_csv('/home/ubuntu/landscape-aesthetics/data/external/scenicornot/scenicornot_color_feature.csv', index=False)\n",
    "\n",
    "# print(\"Color space extraction is complete, results saved in 'scenicornot_color_feature.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95be3a8e-0f35-4c8e-8100-3ef0fc63e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_639315/59454719.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_scores['score_category'] = pd.qcut(df_scores['average'], q=10, labels=False)\n",
      "/tmp/ipykernel_639315/59454719.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df_scores.groupby('score_category').apply(lambda x: x.sample(n=50, random_state=42)).reset_index(drop=True)\n",
      "Processing Images: 100%|██████████████████████| 500/500 [03:25<00:00,  2.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Set paths\n",
    "data_path = '/home/ubuntu/landscape-aesthetics/data/external/scenicornot/scenicornot.metadata.csv'\n",
    "image_folder = Path('/home/ubuntu/landscape-aesthetics/data/external/scenicornot') \n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "df_scores = data[['filename', 'average']].copy()\n",
    "\n",
    "# Divide the scores into 10 equal-frequency intervals\n",
    "df_scores['score_category'] = pd.qcut(df_scores['average'], q=10, labels=False)\n",
    "\n",
    "sampled_df = df_scores.groupby('score_category', group_keys=False).apply(lambda x: x.sample(n=50, random_state=42)).reset_index(drop=True)\n",
    "# Define image transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n",
    "])\n",
    "\n",
    "# List to store image paths and dominant colors\n",
    "dominant_colors_data = []\n",
    "\n",
    "# Loop through each image with a progress bar\n",
    "for idx in tqdm(range(len(sampled_df)), desc=\"Processing Images\"):\n",
    "    img_name = sampled_df.iloc[idx]['filename']\n",
    "    image_path = image_folder / Path(img_name)\n",
    "    try:\n",
    "        # Read and process the image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if image is None:\n",
    "            print(f\"Warning: Unable to load image {image_path}, skipping...\")\n",
    "            continue  # Skip if the image cannot be loaded\n",
    "\n",
    "        # Apply transformations\n",
    "        img = data_transforms(image)\n",
    "        \n",
    "        # Extract dominant colors\n",
    "        image_np = np.array(image)\n",
    "        image_np = image_np.reshape(-1, 3)  # Reshape image data to 2D array\n",
    "        kmeans = KMeans(n_clusters=8, random_state=0).fit(image_np)\n",
    "        dominant_color = kmeans.cluster_centers_  # Get top three dominant colors\n",
    "        \n",
    "        # Add image path and dominant colors to results list\n",
    "        dominant_colors_data.append([str(image_path), *dominant_color.flatten()])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        continue  # Skip this image and proceed if an error occurs\n",
    "\n",
    "# Save results to CSV file\n",
    "output_df = pd.DataFrame(dominant_colors_data, columns=['image_path', 'R1', 'G1', 'B1', 'R2', 'G2', 'B2', 'R3', 'G3', 'B3', 'R4', 'G4', 'B4', 'R5', 'G5', 'B5', 'R6', 'G6', 'B6', 'R7', 'G7', 'B7', 'R8', 'G8', 'B8'])\n",
    "output_df.to_csv('/home/ubuntu/landscape-aesthetics/reports/dominant_colors_8.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dce23b0-b7eb-48d0-bd75-588ee289761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_640366/671887017.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df_scores.groupby('score_category', group_keys=False).apply(lambda x: x.sample(n=500, random_state=42)).reset_index(drop=True)\n",
      "Processing Images: 100%|███████████████████| 5000/5000 [00:38<00:00, 128.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "def get_dominant_colors(image_path, bins_per_channel=8, top_colors=8):\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, \n",
    "                        [bins_per_channel] * 3, [0, 256] * 3)\n",
    "    hist = hist.flatten()\n",
    "    \n",
    "    \n",
    "    bin_size = 256 // bins_per_channel\n",
    "    bin_centers = np.arange(bin_size // 2, 256, bin_size)\n",
    "    color_bins = [(r, g, b) for r in bin_centers for g in bin_centers for b in bin_centers]\n",
    "    \n",
    "    \n",
    "    color_freq = Counter({color_bins[i]: hist[i] for i in range(len(hist))})\n",
    "    dominant_colors = [color for color, freq in color_freq.most_common(top_colors)]\n",
    "    \n",
    "    return dominant_colors\n",
    "\n",
    "\n",
    "# Set paths\n",
    "data_path = '/home/ubuntu/landscape-aesthetics/data/external/scenicornot/scenicornot.metadata.csv'\n",
    "image_folder = Path('/home/ubuntu/landscape-aesthetics/data/external/scenicornot') \n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "df_scores = data[['filename', 'average']].copy()\n",
    "\n",
    "# Divide the scores into 10 equal-frequency intervals\n",
    "df_scores['score_category'] = pd.qcut(df_scores['average'], q=10, labels=False)\n",
    "\n",
    "sampled_df = df_scores.groupby('score_category', group_keys=False).apply(lambda x: x.sample(n=500, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# List to store image paths and dominant colors\n",
    "dominant_colors_data = []\n",
    "\n",
    "# Loop through each image with a progress bar\n",
    "for idx in tqdm(range(len(sampled_df)), desc=\"Processing Images\"):\n",
    "    img_name = sampled_df.iloc[idx]['filename']\n",
    "    image_path = image_folder / Path(img_name)\n",
    "    try:\n",
    "        # Read and process the image\n",
    "        dominant_colors = get_dominant_colors(image_path)\n",
    "        # Add image path and dominant colors to results list\n",
    "        dominant_colors_data.append([str(image_path), *np.ravel(dominant_colors)])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        continue  # Skip this image and proceed if an error occurs\n",
    "\n",
    "# Save results to CSV file\n",
    "output_df = pd.DataFrame(dominant_colors_data, columns=['image_path', 'R1', 'G1', 'B1', 'R2', 'G2', 'B2', 'R3', 'G3', 'B3', 'R4', 'G4', 'B4', 'R5', 'G5', 'B5', 'R6', 'G6', 'B6', 'R7', 'G7', 'B7', 'R8', 'G8', 'B8'])\n",
    "output_df.to_csv('/home/ubuntu/landscape-aesthetics/reports/dominant_colors_hist_8.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532381ae-5cf1-4be8-bbc4-f9921066735a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
