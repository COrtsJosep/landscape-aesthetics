{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcd04de6-806c-4322-90ce-b6952cee2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef36107-85f2-4e01-bf23-edb9c5e35bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# Download the required files.\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check if the request was successful.\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {save_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63da00d7-95cf-4942-8dba-5b571d48c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # hacky way to deal with the Pytorch 1.0 update\n",
    "def recursion_change_bn(module):\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module.track_running_stats = 1\n",
    "    else:\n",
    "        for i, (name, module1) in enumerate(module._modules.items()):\n",
    "            module1 = recursion_change_bn(module1)\n",
    "    return module\n",
    "\n",
    "def load_labels(data_dir='../../data/external/Places365'):\n",
    "    # Create a data directory (if it does not exist).\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # scene category relevant\n",
    "    file_name_category = os.path.join(data_dir, 'categories_places365.txt')\n",
    "    if not os.path.exists(file_name_category):\n",
    "        print(f\"{file_name_category} does not exist. Downloading...\")\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "        download_file(synset_url, file_name_category)\n",
    "    classes = list()\n",
    "    try:\n",
    "        with open(file_name_category) as class_file:\n",
    "            for line in class_file:\n",
    "                classes.append(line.strip().split(' ')[0][3:])\n",
    "        classes = tuple(classes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_category}: {e}\")\n",
    "\n",
    "    # indoor and outdoor relevant\n",
    "    file_name_IO = os.path.join(data_dir, 'IO_places365.txt')\n",
    "    if not os.path.exists(file_name_IO):\n",
    "        print(f\"{file_name_IO} does not exist. Downloading...\")\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/IO_places365.txt'\n",
    "        download_file(synset_url, file_name_IO)\n",
    "    try:\n",
    "        with open(file_name_IO) as f:\n",
    "            lines = f.readlines()\n",
    "            labels_IO = []\n",
    "            for line in lines:\n",
    "                items = line.rstrip().split()\n",
    "                labels_IO.append(int(items[-1]) - 1)  # 0 is indoor, 1 is outdoor\n",
    "        labels_IO = np.array(labels_IO)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_IO}: {e}\")\n",
    "\n",
    "    # scene attribute relevant\n",
    "    file_name_attribute = os.path.join(data_dir, 'labels_sunattribute.txt')\n",
    "    if not os.path.exists(file_name_attribute):\n",
    "        print(f\"{file_name_attribute} does not exist. Downloading...\")\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/labels_sunattribute.txt'\n",
    "        download_file(synset_url, file_name_attribute)\n",
    "    try:\n",
    "        with open(file_name_attribute) as f:\n",
    "            lines = f.readlines()\n",
    "            labels_attribute = [item.rstrip() for item in lines]\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_attribute}: {e}\")\n",
    "\n",
    "    file_name_W = os.path.join(data_dir, 'W_sceneattribute_wideresnet18.npy')\n",
    "    if not os.path.exists(file_name_W):\n",
    "        print(f\"{file_name_W} does not exist. Downloading...\")\n",
    "        synset_url = 'http://places2.csail.mit.edu/models_places365/W_sceneattribute_wideresnet18.npy'\n",
    "        download_file(synset_url, file_name_W)\n",
    "    try:\n",
    "        W_attribute = np.load(file_name_W)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_W}: {e}\")\n",
    "        W_attribute = None\n",
    "\n",
    "    return classes, labels_IO, labels_attribute, W_attribute\n",
    "\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(np.squeeze(output.data.cpu().numpy()))\n",
    "\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "def returnTF():\n",
    "# load the image transformer\n",
    "    tf = trn.Compose([\n",
    "        trn.Resize((256,256)),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return tf\n",
    "\n",
    "def load_model(model_dir='../../data/external/Places365/model'):\n",
    "    # Create a data directory (if it does not exist).\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model_file = os.path.join(model_dir, 'wideresnet18_places365.pth.tar')\n",
    "    script_file = os.path.join(model_dir, 'wideresnet.py')\n",
    "\n",
    "    # Download the model files.\n",
    "    if not os.path.exists(model_file):\n",
    "        print(f\"{model_file} does not exist. Downloading...\")\n",
    "        model_url = 'http://places2.csail.mit.edu/models_places365/wideresnet18_places365.pth.tar'\n",
    "        download_file(model_url, model_file)\n",
    "\n",
    "    # Download the script files.\n",
    "    if not os.path.exists(script_file):\n",
    "        print(f\"{script_file} does not exist. Downloading...\")\n",
    "        script_url = 'https://raw.githubusercontent.com/csailvision/places365/master/wideresnet.py'\n",
    "        download_file(script_url, script_file)\n",
    "\n",
    "    # Add the script files directory to the Python path.\n",
    "    sys.path.append(model_dir)\n",
    "\n",
    "    # Import the model.\n",
    "    try:\n",
    "        import wideresnet\n",
    "        model = wideresnet.resnet18(num_classes=365)\n",
    "        checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage, weights_only=True)\n",
    "        state_dict = {str.replace(k, 'module.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "        # Change the BatchNorm and avgpool layers.\n",
    "        model = recursion_change_bn(model)\n",
    "        model.avgpool = torch.nn.AvgPool2d(kernel_size=14, stride=1, padding=0)\n",
    "        model.eval()\n",
    "\n",
    "        # Set feature extraction hooks.\n",
    "        features_names = ['layer4', 'avgpool']\n",
    "        for name in features_names:\n",
    "            model._modules.get(name).register_forward_hook(hook_feature)\n",
    "\n",
    "        print(\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing wideresnet module: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2305e52-7b88-4b4d-ae95-27883c9e8681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "classes, labels_IO, labels_attribute, W_attribute = load_labels()\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "tf = returnTF() # image transformer\n",
    "\n",
    "# get the softmax weight\n",
    "params = list(model.parameters())\n",
    "weight_softmax = params[-2].data.numpy()\n",
    "weight_softmax[weight_softmax<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce9a4058-2bfc-43e4-a250-2c1d30343dea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_blobs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m input_img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mVariable(tf(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m logit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m h_x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logit, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     21\u001b[0m probs, idx \u001b[38;5;241m=\u001b[39m h_x\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/landscape-aesthetics/src/models/../../data/external/Places365/model/wideresnet.py:149\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    148\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m--> 149\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    152\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/geoproject/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/geoproject/lib/python3.12/site-packages/torch/nn/modules/module.py:1616\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1616\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1619\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[0;32mIn[10], line 73\u001b[0m, in \u001b[0;36mhook_feature\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhook_feature\u001b[39m(module, \u001b[38;5;28minput\u001b[39m, output):\n\u001b[0;32m---> 73\u001b[0m    \u001b[43mfeatures_blobs\u001b[49m\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39msqueeze(output\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_blobs' is not defined"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "data_path = '/home/ubuntu/landscape-aesthetics/data/processed/landscape_handmade/landscapes.csv'\n",
    "image_folder = Path('/home/ubuntu/landscape-aesthetics')\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "\n",
    "# Open and preprocess the image.\n",
    "image_paths = data.iloc[:, 0]  \n",
    "labels = data.iloc[:, 1]       \n",
    "\n",
    "for img_path, label in zip(image_paths, labels):\n",
    "    test_image_path = image_folder / img_path\n",
    "    img = Image.open(test_image_path)\n",
    "    input_img = torch.autograd.Variable(tf(img).unsqueeze(0))\n",
    "    \n",
    "    # forward pass\n",
    "    logit = model.forward(input_img)\n",
    "    h_x = F.softmax(logit, 1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    probs = probs.numpy()\n",
    "    idx = idx.numpy()\n",
    "    \n",
    "    # output the IO prediction\n",
    "    io_image = np.mean(labels_IO[idx[:10]]) # vote for the indoor or outdoor\n",
    "    if io_image < 0.5:\n",
    "        print('--TYPE OF ENVIRONMENT: indoor')\n",
    "    else:\n",
    "        print('--TYPE OF ENVIRONMENT: outdoor')\n",
    "    \n",
    "    # output the prediction of scene category\n",
    "    print('--SCENE CATEGORIES:')\n",
    "    for i in range(0, 5):\n",
    "        print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n",
    "    \n",
    "    # output the scene attributes\n",
    "    responses_attribute = W_attribute.dot(features_blobs[1])\n",
    "    idx_a = np.argsort(responses_attribute)\n",
    "    print('--SCENE ATTRIBUTES:')\n",
    "    print(', '.join([labels_attribute[idx_a[i]] for i in range(-1,-10,-1)]))\n",
    "    \n",
    "    # generate class activation mapping\n",
    "    print('Class activation map is saved as cam.jpg')\n",
    "    CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0116a2-9958-46c8-9f45-72ed421f07c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
