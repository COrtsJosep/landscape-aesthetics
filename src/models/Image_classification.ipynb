{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd04de6-806c-4322-90ce-b6952cee2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef36107-85f2-4e01-bf23-edb9c5e35bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# Download the required files.\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check if the request was successful.\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {save_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da00d7-95cf-4942-8dba-5b571d48c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # hacky way to deal with the Pytorch 1.0 update\n",
    "def recursion_change_bn(module):\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module.track_running_stats = 1\n",
    "    else:\n",
    "        for i, (name, module1) in enumerate(module._modules.items()):\n",
    "            module1 = recursion_change_bn(module1)\n",
    "    return module\n",
    "\n",
    "def load_labels(data_dir='../../data/external/Places365'):\n",
    "    # Create a data directory (if it does not exist).\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # scene category relevant\n",
    "    file_name_category = os.path.join(data_dir, 'categories_places365.txt')\n",
    "    if not os.path.exists(file_name_category):\n",
    "        print(f\"{file_name_category} does not exist. Downloading...\")\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "        download_file(synset_url, file_name_category)\n",
    "    classes = list()\n",
    "    try:\n",
    "        with open(file_name_category) as class_file:\n",
    "            for line in class_file:\n",
    "                classes.append(line.strip().split(' ')[0][3:])\n",
    "        classes = tuple(classes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_category}: {e}\")\n",
    "\n",
    "    # indoor and outdoor relevant\n",
    "    file_name_IO = os.path.join(data_dir, 'IO_places365.txt')\n",
    "    if not os.path.exists(file_name_IO):\n",
    "        print(f\"{file_name_IO} does not exist. Downloading...\")\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/IO_places365.txt'\n",
    "        download_file(synset_url, file_name_IO)\n",
    "    try:\n",
    "        with open(file_name_IO) as f:\n",
    "            lines = f.readlines()\n",
    "            labels_IO = []\n",
    "            for line in lines:\n",
    "                items = line.rstrip().split()\n",
    "                labels_IO.append(int(items[-1]) - 1)  # 0 is indoor, 1 is outdoor\n",
    "        labels_IO = np.array(labels_IO)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_IO}: {e}\")\n",
    "\n",
    "    # scene attribute relevant\n",
    "    file_name_attribute = os.path.join(data_dir, 'labels_sunattribute.txt')\n",
    "    if not os.path.exists(file_name_attribute):\n",
    "        print(f\"{file_name_attribute} does not exist. Downloading...\")\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/labels_sunattribute.txt'\n",
    "        download_file(synset_url, file_name_attribute)\n",
    "    try:\n",
    "        with open(file_name_attribute) as f:\n",
    "            lines = f.readlines()\n",
    "            labels_attribute = [item.rstrip() for item in lines]\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_attribute}: {e}\")\n",
    "\n",
    "    file_name_W = os.path.join(data_dir, 'W_sceneattribute_wideresnet18.npy')\n",
    "    if not os.path.exists(file_name_W):\n",
    "        print(f\"{file_name_W} does not exist. Downloading...\")\n",
    "        synset_url = 'http://places2.csail.mit.edu/models_places365/W_sceneattribute_wideresnet18.npy'\n",
    "        download_file(synset_url, file_name_W)\n",
    "    try:\n",
    "        W_attribute = np.load(file_name_W)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_W}: {e}\")\n",
    "        W_attribute = None\n",
    "\n",
    "    return classes, labels_IO, labels_attribute, W_attribute\n",
    "\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(np.squeeze(output.data.cpu().numpy()))\n",
    "\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "def returnTF():\n",
    "# load the image transformer\n",
    "    tf = trn.Compose([\n",
    "        trn.Resize((256,256)),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return tf\n",
    "\n",
    "def load_model(model_dir='../../data/external/Places365/model'):\n",
    "    # Create a data directory (if it does not exist).\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model_file = os.path.join(model_dir, 'wideresnet18_places365.pth.tar')\n",
    "    script_file = os.path.join(model_dir, 'wideresnet.py')\n",
    "\n",
    "    # Download the model files.\n",
    "    if not os.path.exists(model_file):\n",
    "        print(f\"{model_file} does not exist. Downloading...\")\n",
    "        model_url = 'http://places2.csail.mit.edu/models_places365/wideresnet18_places365.pth.tar'\n",
    "        download_file(model_url, model_file)\n",
    "\n",
    "    # Download the script files.\n",
    "    if not os.path.exists(script_file):\n",
    "        print(f\"{script_file} does not exist. Downloading...\")\n",
    "        script_url = 'https://raw.githubusercontent.com/csailvision/places365/master/wideresnet.py'\n",
    "        download_file(script_url, script_file)\n",
    "\n",
    "    # Add the script files directory to the Python path.\n",
    "    sys.path.append(model_dir)\n",
    "\n",
    "    # Import the model.\n",
    "    try:\n",
    "        import wideresnet\n",
    "        model = wideresnet.resnet18(num_classes=365)\n",
    "        checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "        state_dict = {str.replace(k, 'module.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "        # Change the BatchNorm and avgpool layers.\n",
    "        model = recursion_change_bn(model)\n",
    "        model.avgpool = torch.nn.AvgPool2d(kernel_size=14, stride=1, padding=0)\n",
    "        model.eval()\n",
    "\n",
    "        # Set feature extraction hooks.\n",
    "        features_names = ['layer4', 'avgpool']\n",
    "        for name in features_names:\n",
    "            model._modules.get(name).register_forward_hook(hook_feature)\n",
    "\n",
    "        print(\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing wideresnet module: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2305e52-7b88-4b4d-ae95-27883c9e8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, labels_IO, labels_attribute, W_attribute = load_labels()\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "tf = returnTF() # image transformer\n",
    "\n",
    "# get the softmax weight\n",
    "params = list(model.parameters())\n",
    "weight_softmax = params[-2].data.numpy()\n",
    "weight_softmax[weight_softmax<0] = 0\n",
    "\n",
    "# Open and preprocess the image.\n",
    "test_image_path = '../../data/external/Places365/test.jpg'\n",
    "img = Image.open(test_image_path)\n",
    "input_img = torch.autograd.Variable(tf(img).unsqueeze(0))\n",
    "\n",
    "# forward pass\n",
    "logit = model.forward(input_img)\n",
    "h_x = F.softmax(logit, 1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "probs = probs.numpy()\n",
    "idx = idx.numpy()\n",
    "\n",
    "# output the IO prediction\n",
    "io_image = np.mean(labels_IO[idx[:10]]) # vote for the indoor or outdoor\n",
    "if io_image < 0.5:\n",
    "    print('--TYPE OF ENVIRONMENT: indoor')\n",
    "else:\n",
    "    print('--TYPE OF ENVIRONMENT: outdoor')\n",
    "\n",
    "# output the prediction of scene category\n",
    "print('--SCENE CATEGORIES:')\n",
    "for i in range(0, 5):\n",
    "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n",
    "\n",
    "# output the scene attributes\n",
    "responses_attribute = W_attribute.dot(features_blobs[1])\n",
    "idx_a = np.argsort(responses_attribute)\n",
    "print('--SCENE ATTRIBUTES:')\n",
    "print(', '.join([labels_attribute[idx_a[i]] for i in range(-1,-10,-1)]))\n",
    "\n",
    "# generate class activation mapping\n",
    "print('Class activation map is saved as cam.jpg')\n",
    "CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
    "\n",
    "# render the CAM and output\n",
    "img = cv2.imread(test_image_path)\n",
    "height, width, _ = img.shape\n",
    "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0], (width, height)), cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.4 + img * 0.5\n",
    "cam_output_path = '../../data/external/Places365/result/cam.jpg'\n",
    "cv2.imwrite(cam_output_path, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
