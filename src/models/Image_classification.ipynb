{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd04de6-806c-4322-90ce-b6952cee2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef36107-85f2-4e01-bf23-edb9c5e35bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# Download the required files.\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check if the request was successful.\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {save_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63da00d7-95cf-4942-8dba-5b571d48c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # hacky way to deal with the Pytorch 1.0 update\n",
    "def recursion_change_bn(module):\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module.track_running_stats = 1\n",
    "    else:\n",
    "        for i, (name, module1) in enumerate(module._modules.items()):\n",
    "            module1 = recursion_change_bn(module1)\n",
    "    return module\n",
    "\n",
    "def load_labels(data_dir='../../data/external/Places365'):\n",
    "    # Create a data directory (if it does not exist).\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # scene category relevant\n",
    "    file_name_category = os.path.join(data_dir, 'categories_places365.txt')\n",
    "    if not os.path.exists(file_name_category):\n",
    "        print(f\"{file_name_category} does not exist. Downloading...\")\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "        download_file(synset_url, file_name_category)\n",
    "    classes = list()\n",
    "    try:\n",
    "        with open(file_name_category) as class_file:\n",
    "            for line in class_file:\n",
    "                classes.append(line.strip().split(' ')[0][3:])\n",
    "        classes = tuple(classes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_category}: {e}\")\n",
    "\n",
    "    # indoor and outdoor relevant\n",
    "    file_name_IO = os.path.join(data_dir, 'IO_places365.txt')\n",
    "    if not os.path.exists(file_name_IO):\n",
    "        print(f\"{file_name_IO} does not exist. Downloading...\")\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/IO_places365.txt'\n",
    "        download_file(synset_url, file_name_IO)\n",
    "    try:\n",
    "        with open(file_name_IO) as f:\n",
    "            lines = f.readlines()\n",
    "            labels_IO = []\n",
    "            for line in lines:\n",
    "                items = line.rstrip().split()\n",
    "                labels_IO.append(int(items[-1]) - 1)  # 0 is indoor, 1 is outdoor\n",
    "        labels_IO = np.array(labels_IO)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_IO}: {e}\")\n",
    "\n",
    "    # scene attribute relevant\n",
    "    file_name_attribute = os.path.join(data_dir, 'labels_sunattribute.txt')\n",
    "    if not os.path.exists(file_name_attribute):\n",
    "        print(f\"{file_name_attribute} does not exist. Downloading...\")\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/labels_sunattribute.txt'\n",
    "        download_file(synset_url, file_name_attribute)\n",
    "    try:\n",
    "        with open(file_name_attribute) as f:\n",
    "            lines = f.readlines()\n",
    "            labels_attribute = [item.rstrip() for item in lines]\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_attribute}: {e}\")\n",
    "\n",
    "    file_name_W = os.path.join(data_dir, 'W_sceneattribute_wideresnet18.npy')\n",
    "    if not os.path.exists(file_name_W):\n",
    "        print(f\"{file_name_W} does not exist. Downloading...\")\n",
    "        synset_url = 'http://places2.csail.mit.edu/models_places365/W_sceneattribute_wideresnet18.npy'\n",
    "        download_file(synset_url, file_name_W)\n",
    "    try:\n",
    "        W_attribute = np.load(file_name_W)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name_W}: {e}\")\n",
    "        W_attribute = None\n",
    "\n",
    "    return classes, labels_IO, labels_attribute, W_attribute\n",
    "\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(np.squeeze(output.data.cpu().numpy()))\n",
    "\n",
    "def returnTF():\n",
    "# load the image transformer\n",
    "    tf = transforms.Compose([\n",
    "        # transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n",
    "    ])\n",
    "    return tf\n",
    "\n",
    "def load_model(model_dir='../../data/external/Places365/model'):\n",
    "    # Create a data directory (if it does not exist).\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model_file = os.path.join(model_dir, 'wideresnet18_places365.pth.tar')\n",
    "    script_file = os.path.join(model_dir, 'wideresnet.py')\n",
    "\n",
    "    # Download the model files.\n",
    "    if not os.path.exists(model_file):\n",
    "        print(f\"{model_file} does not exist. Downloading...\")\n",
    "        model_url = 'http://places2.csail.mit.edu/models_places365/wideresnet18_places365.pth.tar'\n",
    "        download_file(model_url, model_file)\n",
    "\n",
    "    # Download the script files.\n",
    "    if not os.path.exists(script_file):\n",
    "        print(f\"{script_file} does not exist. Downloading...\")\n",
    "        script_url = 'https://raw.githubusercontent.com/csailvision/places365/master/wideresnet.py'\n",
    "        download_file(script_url, script_file)\n",
    "\n",
    "    # Add the script files directory to the Python path.\n",
    "    sys.path.append(model_dir)\n",
    "\n",
    "    # Import the model.\n",
    "    try:\n",
    "        import wideresnet\n",
    "        model = wideresnet.resnet18(num_classes=365)\n",
    "        checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage, weights_only=True)\n",
    "        state_dict = {str.replace(k, 'module.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "        # Change the BatchNorm and avgpool layers.\n",
    "        model = recursion_change_bn(model)\n",
    "        model.avgpool = torch.nn.AvgPool2d(kernel_size=16, stride=1, padding=0)\n",
    "        model.eval()\n",
    "\n",
    "        # Set feature extraction hooks.\n",
    "        features_names = ['layer4', 'avgpool']\n",
    "        for name in features_names:\n",
    "            model._modules.get(name).register_forward_hook(hook_feature)\n",
    "\n",
    "        print(\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing wideresnet module: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2305e52-7b88-4b4d-ae95-27883c9e8681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "classes, labels_IO, labels_attribute, W_attribute = load_labels()\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "tf = returnTF() # image transformer\n",
    "\n",
    "# get the softmax weight\n",
    "params = list(model.parameters())\n",
    "weight_softmax = params[-2].data.numpy()\n",
    "weight_softmax[weight_softmax<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a4058-2bfc-43e4-a250-2c1d30343dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "data_path = '/home/ubuntu/landscape-aesthetics/data/external/scenicornot/scenicornot.metadata.csv'\n",
    "image_folder = Path('/home/ubuntu/landscape-aesthetics/data/external/scenicornot') \n",
    "\n",
    "data = pd.read_csv(data_path).head(10)\n",
    "image_paths = data.iloc[:, 0]  \n",
    "labels = data.iloc[:, 1]       \n",
    "\n",
    "tf = returnTF()\n",
    "\n",
    "for img_path, label in zip(image_paths, labels):\n",
    "    test_image_path = image_folder / img_path\n",
    "    img = Image.open(test_image_path)\n",
    "    input_img = torch.autograd.Variable(tf(img).unsqueeze(0))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    # forward pass\n",
    "    features_blobs = []\n",
    "    logit = model.forward(input_img)\n",
    "    h_x = F.softmax(logit, 1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    probs = probs.numpy()\n",
    "    idx = idx.numpy()\n",
    "    \n",
    "    # output the IO prediction\n",
    "    io_image = np.mean(labels_IO[idx[:10]]) # vote for the indoor or outdoor\n",
    "    # output the prediction of scene category\n",
    "    print('--SCENE CATEGORIES:')\n",
    "    for i in range(0, 3):\n",
    "        print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n",
    "    \n",
    "    # output the scene attributes\n",
    "    responses_attribute = W_attribute.dot(features_blobs[1])\n",
    "    idx_a = np.argsort(responses_attribute)\n",
    "    print('--SCENE ATTRIBUTES:')\n",
    "    print(', '.join([labels_attribute[idx_a[i]] for i in range(-1,-10,-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99e0c7c4-d239-4aae-94d2-8c8cb15d03b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same types of landscape: 306\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '/home/ubuntu/landscape-aesthetics/data/external/Places365/categories_places365.txt'\n",
    "\n",
    "df1 = pd.read_csv(data_path, delimiter=r'\\s+', names=['type', 'id'], engine='python')\n",
    "df2 = pd.read_csv('/home/ubuntu/landscape-aesthetics/data/external/ADEChallengeData2016/sceneCategories.txt', delimiter=r'\\s+', names=['id', 'type'], engine='python') \n",
    "\n",
    "df1['type'] = df1['type'].str.replace(r'^.*/', '', regex=True)\n",
    "\n",
    "scenery_set1 = set(df1.iloc[:,0].unique())\n",
    "common_df2 = df2[df2['type'].isin(scenery_set1)]\n",
    "common_type = len(common_df2['type'].unique())\n",
    "\n",
    "common_df2.to_csv('common_landscape_types_in_df2.csv', columns=['id', 'type'], index=False)\n",
    "\n",
    "print(f\"Same types of landscape: {common_type}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714fbb5a-86ae-4a96-a6dd-d522ff652b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
